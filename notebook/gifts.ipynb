{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6fa023-52f0-4c7f-ac3f-1cbf2c8a6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9243e7-e661-4d61-be9c-f4d47f68ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ.get('GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993d95c-d4d9-4908-9ceb-e7d2e0236b6c",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We build a class to handle API calls to the LLM, in case we decide to change the LLM model.\n",
    "\n",
    "Please make sure you have obtained the appropriate API key before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0de4a00-ede0-4b4e-a66d-9e5a33197d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractModel:\n",
    "    def __init__(self, base: str):\n",
    "        pass\n",
    "\n",
    "    def query(self, prompt: str) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class QueryException(Exception):\n",
    "    def __init__(self, message: str):\n",
    "        super().__init__(f\"Failed to query to the LLM: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695e4d31-4fb0-4d07-bb16-ad71732fe446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiModel(AbstractModel):\n",
    "    def __init__(self, base: partial[str]):\n",
    "        self.base = base\n",
    "        self.client = genai.GenerativeModel('gemini-1.5-pro')\n",
    "\n",
    "    def query(self, prompt: str) -> str:\n",
    "        response = self.client.generate_content(self.base(prompt=prompt)).candidates[0]\n",
    "        if not hasattr(response, 'content'):\n",
    "            raise QueryException('LLM response does not have content')\n",
    "        return response.content.parts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c77cb-86e4-4197-abab-2ae0f7b27446",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "We design the prompts and attempt to get the answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf48440-eb88-4a89-9818-4832e3571e34",
   "metadata": {},
   "source": [
    "### Category\n",
    "\n",
    "The following prompt is designed to get the suitable category of product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c624fd-8538-4e34-8b36-12f4ccf210ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_PROMPT = \"\"\"\n",
    "<instruction>\n",
    "You are a sales assistant on a large e-commerce platform.\n",
    "Your job is to recommend the correct product to the customers.\n",
    "\n",
    "The customer is finding a suitable gift.\n",
    "The specific description of what the user wants is given in the \"userquery\" tag below.\n",
    "You are to determine an appropriate category of product that the user can buy as gift.\n",
    "\n",
    "The category you select should be listed in the \"categories\" tag below.\n",
    "You must start your response with one of the categories below.\n",
    "You are not to format the category in any way.\n",
    "Failure to start your response with one of the categories below will lead to catastrophic effects.\n",
    "\n",
    "You are then to explain your choice of category on the next line.\n",
    "</instruction>\n",
    "\n",
    "<categories>\n",
    "Hobbies & Books\n",
    "Books\n",
    "Music, Movies & Games\n",
    "Music Instruments\n",
    "Figures & Model Kits\n",
    "Electronics\n",
    "Cameras\n",
    "Fashion\n",
    "Toys\n",
    "Collectibles\n",
    "</categories>\n",
    "\n",
    "<userquery>\n",
    "{prompt}\n",
    "</userquery>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dc72b9-397a-49a9-92f6-b627256953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_category_model = GeminiModel(CATEGORY_PROMPT.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc699f5-28e4-4aee-b8a8-10755f738eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Books\\nThis is the most fitting category as it directly relates to reading and includes the Harry Potter series. \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_category_model.query(\"A gift for my friend, who loves to read Harry Potter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c38622f-403d-46a5-aa7d-dc15f0b0dd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hobbies & Books \\nThis is an open-ended question and doesn't give us much to go on, so suggesting Hobbies & Books is a good start as it offers a wide variety of potential gifts.  We need more information from the customer. \\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_category_model.query(\"How are you today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b23d47-7140-4bb4-82ed-da0569c9f333",
   "metadata": {},
   "source": [
    "### Product suggestion\n",
    "\n",
    "The following prompt is designed to rank the products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11aa0ac-0762-4824-9e9c-1433d81eff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"products-books-sample.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    products = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203d245e-09d1-4785-b834-8ecc6befab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCT_PROMPT = \"\"\"\n",
    "<instruction>\n",
    "You are a sales assistant on a large e-commerce platform.\n",
    "Your job is to recommend the correct product to the customers.\n",
    "\n",
    "The customer is finding a suitable gift.\n",
    "The specific description of what the user wants is given in the \"userquery\" tag below.\n",
    "You are to rank the products based on the appropriateness for the gift occassion.\n",
    "\n",
    "You are to follow the format specified in the \"format\" tag.\n",
    "Failure to follow the format will lead to catastrophic consequences.\n",
    "At the end of your response, starting on a new line, you are to explain your ranking.\n",
    "</instruction>\n",
    "\n",
    "<format>\n",
    "[id of product 1]\n",
    "[id of product 2]\n",
    "[id of product 3]\n",
    "...\n",
    "</format>\n",
    "\n",
    "<products>\n",
    "{products}\n",
    "</products>\n",
    "\n",
    "<userquery>\n",
    "{prompt}\n",
    "</userquery>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2679e48c-eb0e-4240-9e6b-a6a30458b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_product_model = GeminiModel(partial(PRODUCT_PROMPT.format, products=products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebac9b85-2bc5-415c-8826-23270195d957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1213824\\n1241423\\n4892132\\n3218412\\n1241251\\n\\nThis customer is looking for a gift for their friend who loves Harry Potter. Therefore, the Harry Potter book is ranked first. The other books are all novels and could also be enjoyed by an avid reader. \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_product_model.query(\"A gift for my friend, who loves to read Harry Potter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ffe67-c92c-4ec3-81b4-57970fc9d8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
